
@online{Wen2020-ez,
title         = "Time Series Data Augmentation for Deep Learning: A Survey",
author        = "Wen, Qingsong and Sun, Liang and Yang, Fan and Song, Xiaomin
                 and Gao, Jingkun and Wang, Xue and Xu, Huan",
abstract      = "Deep learning performs remarkably well on many time series
                 analysis tasks recently. The superior performance of deep
                 neural networks relies heavily on a large number of training
                 data to avoid overfitting. However, the labeled data of many
                 real-world time series applications may be limited such as
                 classification in medical time series and anomaly detection
                 in AIOps. As an effective way to enhance the size and
                 quality of the training data, data augmentation is crucial
                 to the successful application of deep learning models on
                 time series data. In this paper, we systematically review
                 different data augmentation methods for time series. We
                 propose a taxonomy for the reviewed methods, and then
                 provide a structured review for these methods by
                 highlighting their strengths and limitations. We also
                 empirically compare different data augmentation methods for
                 different tasks including time series classification,
                 anomaly detection, and forecasting. Finally, we discuss and
                 highlight five future directions to provide useful research
                 guidance.",
month         =  "27~" # feb,
year          =  2020,
url           = "http://arxiv.org/abs/2002.12478",
file          = "All Papers/WEN/Wen et al. 2020 - Time Series Data Augmentation for Deep Learning - A Survey.pdf",
archivePrefix = "arXiv",
eprint        = "2002.12478",
primaryClass  = "cs.LG",
arxivid       = "2002.12478",
journal       = "arXiv"
}


@INPROCEEDINGS{Le_Guennec2016-zi,
title     = "Data augmentation for time series classification using
             convolutional neural networks",
booktitle = "{ECML/PKDD} workshop on advanced analytics and learning on
             temporal data",
author    = "Le Guennec, Arthur and Malinowski, Simon and Tavenard, Romain",
year      =  2016,
url       = "https://halshs.archives-ouvertes.fr/halshs-01357973/document",
file      = "All Papers/LE GUENNEC/Le Guennec et al. 2016 - Data augmentation for time series classification using convolutional neural networks.pdf"
}


@ARTICLE{Shorten2019-ty,
  title     = "A survey on Image Data Augmentation for Deep Learning",
  author    = "Shorten, Connor and Khoshgoftaar, Taghi M",
  abstract  = "Deep convolutional neural networks have performed remarkably
               well on many Computer Vision tasks. However, these networks are
               heavily reliant on big data to avoid overfitting. Overfitting
               refers to the phenomenon when a network learns a function with
               very high variance such as to perfectly model the training data.
               Unfortunately, many application domains do not have access to
               big data, such as medical image analysis. This survey focuses on
               Data Augmentation, a data-space solution to the problem of
               limited data. Data Augmentation encompasses a suite of
               techniques that enhance the size and quality of training
               datasets such that better Deep Learning models can be built
               using them. The image augmentation algorithms discussed in this
               survey include geometric transformations, color space
               augmentations, kernel filters, mixing images, random erasing,
               feature space augmentation, adversarial training, generative
               adversarial networks, neural style transfer, and meta-learning.
               The application of augmentation methods based on GANs are
               heavily covered in this survey. In addition to augmentation
               techniques, this paper will briefly discuss other
               characteristics of Data Augmentation such as test-time
               augmentation, resolution impact, final dataset size, and
               curriculum learning. This survey will present existing methods
               for Data Augmentation, promising developments, and meta-level
               decisions for implementing Data Augmentation. Readers will
               understand how Data Augmentation can improve the performance of
               their models and expand limited datasets to take advantage of
               the capabilities of big data.",
  journal   = "Journal of Big Data",
  publisher = "SpringerOpen",
  volume    =  6,
  number    =  1,
  pages     = "1--48",
  month     =  "6~" # jul,
  year      =  2019,
  url       = "https://journalofbigdata.springeropen.com/articles/10.1186/s40537-019-0197-0",
  file      = "All Papers/SHORTEN/Shorten and Khoshgoftaar 2019 - A survey on Image Data Augmentation for Deep Learning.pdf",
  language  = "en",
  issn      = "2196-1115, 2196-1115",
  doi       = "10.1186/s40537-019-0197-0"
}


@online{Hasibi2019-in,
  title         = "Augmentation Scheme for Dealing with Imbalanced Network
                   Traffic Classification Using Deep Learning",
  author        = "Hasibi, Ramin and Shokri, Matin and Dehghan, Mehdi",
  abstract      = "One of the most important tasks in network management is
                   identifying different types of traffic flows. As a result, a
                   type of management service, called Network Traffic
                   Classifier (NTC), has been introduced. One type of NTCs that
                   has gained huge attention in recent years applies deep
                   learning on packets in order to classify flows. Internet is
                   an imbalanced environment i.e., some classes of applications
                   are a lot more populated than others e.g., HTTP.
                   Additionally, one of the challenges in deep learning methods
                   is that they do not perform well in imbalanced environments
                   in terms of evaluation metrics such as precision, recall,
                   and $\mathrm\{F_1\}$ measure. In order to solve this
                   problem, we recommend the use of augmentation methods to
                   balance the dataset. In this paper, we propose a novel data
                   augmentation approach based on the use of Long Short Term
                   Memory (LSTM) networks for generating traffic flow patterns
                   and Kernel Density Estimation (KDE) for replicating the
                   numerical features of each class. First, we use the LSTM
                   network in order to learn and generate the sequence of
                   packets in a flow for classes with less population. Then, we
                   complete the features of the sequence with generating random
                   values based on the distribution of a certain feature, which
                   will be estimated using KDE. Finally, we compare the
                   training of a Convolutional Recurrent Neural Network (CRNN)
                   in large-scale imbalanced, sampled, and augmented datasets.
                   The contribution of our augmentation scheme is then
                   evaluated on all of the datasets through measurements of
                   precision, recall, and F1 measure for every class of
                   application. The results demonstrate that our scheme is well
                   suited for network traffic flow datasets and improves the
                   performance of deep learning algorithms when it comes to
                   above-mentioned metrics.",
  month         =  "1~" # jan,
  year          =  2019,
  url           = "http://arxiv.org/abs/1901.00204",
  file          = "All Papers/HASIBI/Hasibi et al. 2019 - Augmentation Scheme for Dealing with Imbalanced Network Traffic Classification Using Deep Learning.pdf",
  archivePrefix = "arXiv",
  eprint        = "1901.00204",
  primaryClass  = "cs.NI",
  arxivid       = "1901.00204"
}


@online{Iwana2020-oc,
  title         = "An Empirical Survey of Data Augmentation for Time Series
                   Classification with Neural Networks",
  author        = "Iwana, Brian Kenji and Uchida, Seiichi",
  abstract      = "In recent times, deep artificial neural networks have
                   achieved many successes in pattern recognition. Part of this
                   success can be attributed to the reliance on big data to
                   increase generalization. However, in the field of time
                   series recognition, many datasets are often very small. One
                   method of addressing this problem is through the use of data
                   augmentation. In this paper, we survey data augmentation
                   techniques for time series and their application to time
                   series classification with neural networks. We propose a
                   taxonomy and outline the four families in time series data
                   augmentation, including transformation-based methods,
                   pattern mixing, generative models, and decomposition
                   methods. Furthermore, we empirically evaluate 12 time series
                   data augmentation methods on 128 time series classification
                   datasets with six different types of neural networks.
                   Through the results, we are able to analyze the
                   characteristics, advantages and disadvantages, and
                   recommendations of each data augmentation method. This
                   survey aims to help in the selection of time series data
                   augmentation for neural network applications.",
  month         =  "31~" # jul,
  year          =  2020,
  url           = "http://arxiv.org/abs/2007.15951",
  file          = "All Papers/IWANA/Iwana and Uchida 2020 - An Empirical Survey of Data Augmentation for Time Series Classification with Neural Networks.pdf",
  archivePrefix = "arXiv",
  eprint        = "2007.15951",
  primaryClass  = "cs.LG",
  arxivid       = "2007.15951"
}
