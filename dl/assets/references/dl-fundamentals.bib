@online{Liu2020-yh,
title         = "Self-supervised Learning: Generative or Contrastive",
author        = "Liu, Xiao and Zhang, Fanjin and Hou, Zhenyu and Wang, Zhaoyu
                 and Mian, Li and Zhang, Jing and Tang, Jie",
abstract      = "Deep supervised learning has achieved great success in the
                 last decade. However, its deficiencies of dependence on
                 manual labels and vulnerability to attacks have driven
                 people to explore a better solution. As an alternative,
                 self-supervised learning attracts many researchers for its
                 soaring performance on representation learning in the last
                 several years. Self-supervised representation learning
                 leverages input data itself as supervision and benefits
                 almost all types of downstream tasks. In this survey, we
                 take a look into new self-supervised learning methods for
                 representation in computer vision, natural language
                 processing, and graph learning. We comprehensively review
                 the existing empirical methods and summarize them into three
                 main categories according to their objectives: generative,
                 contrastive, and generative-contrastive (adversarial). We
                 further investigate related theoretical analysis work to
                 provide deeper thoughts on how self-supervised learning
                 works. Finally, we briefly discuss open problems and future
                 directions for self-supervised learning. An outline slide
                 for the survey is provided.",
month         =  "15~" # jun,
year          =  2020,
url           = "http://arxiv.org/abs/2006.08218",
file          = "All Papers/LIU/Liu et al. 2020 - Self-supervised Learning - Generative or Contrastive.pdf",
archivePrefix = "arXiv",
eprint        = "2006.08218",
primaryClass  = "cs.LG",
arxivid       = "2006.08218"
}



@online{Le_Cun2006-ta,
  title  = "A Tutorial on {Energy-Based} Learning",
  author = "Le Cun, Yann and Chopra, Sumit and Hadsell, Raia and Ranzato,
            Marc'aurelio and Huang, Fu Jie",
  year   =  2006,
  file   = "All Papers/LE CUN/Le Cun et al. 2006 - A Tutorial on Energy-Based Learning.pdf"
}


@online{Luo2022-hz,
  title         = "Understanding Diffusion Models: A Unified Perspective",
  author        = "Luo, Calvin",
  abstract      = "Diffusion models have shown incredible capabilities as
                   generative models; indeed, they power the current
                   state-of-the-art models on text-conditioned image generation
                   such as Imagen and DALL-E 2. In this work we review,
                   demystify, and unify the understanding of diffusion models
                   across both variational and score-based perspectives. We
                   first derive Variational Diffusion Models (VDM) as a special
                   case of a Markovian Hierarchical Variational Autoencoder,
                   where three key assumptions enable tractable computation and
                   scalable optimization of the ELBO. We then prove that
                   optimizing a VDM boils down to learning a neural network to
                   predict one of three potential objectives: the original
                   source input from any arbitrary noisification of it, the
                   original source noise from any arbitrarily noisified input,
                   or the score function of a noisified input at any arbitrary
                   noise level. We then dive deeper into what it means to learn
                   the score function, and connect the variational perspective
                   of a diffusion model explicitly with the Score-based
                   Generative Modeling perspective through Tweedie's Formula.
                   Lastly, we cover how to learn a conditional distribution
                   using diffusion models via guidance.",
  month         =  "25~" # aug,
  year          =  2022,
  url           = "http://arxiv.org/abs/2208.11970",
  file          = "All Papers/LUO/Luo 2022 - Understanding Diffusion Models - A Unified Perspective.pdf",
  copyright     = "http://creativecommons.org/licenses/by/4.0/",
  archivePrefix = "arXiv",
  eprint        = "2208.11970",
  primaryClass  = "cs.LG",
  arxivid       = "2208.11970"
}
