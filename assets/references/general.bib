@article{dimensionsai,
 abstract = {Dimensions is a new scholarly search database that focuses on the broader set of use cases that academics now face. By including awarded grants, patents, and clinical trials alongside publication and Altmetric attention data, Dimensions goes beyond the standard publication-citation ecosystem to give the user a much greater sense of context of a piece of research. All entities in the graph may be linked to all other entities. Thus, a patent may be linked to a grant, if an appropriate reference is made. Books, book chapters, and conference proceedings are included in the publication index. All entities are treated as first-class objects and are mapped to a database of research institutions and a standard set of research classifications via machine-learning techniques. This article gives an overview of the methodology of construction of the Dimensions dataset and user interface.},
 author = {Hook, Daniel W. and Porter, Simon J. and Herzog, Christian},
 doi = {10.3389/frma.2018.00023},
 journal = {Frontiers in Research Metrics and Analytics},
 keywords = {},
 note = {https://www.frontiersin.org/articles/10.3389/frma.2018.00023/pdf},
 number = {},
 pages = {23},
 title = {Dimensions: Building Context for Search and Evaluation},
 url = {https://app.dimensions.ai/details/publication/pub.1106289502},
 volume = {3},
 year = {2018}
}


@online{Millidge2020-mr,
  title         = "Predictive Coding Approximates Backprop along Arbitrary
                   Computation Graphs",
  author        = "Millidge, Beren and Tschantz, Alexander and Buckley,
                   Christopher L",
  abstract      = "Backpropagation of error (backprop) is a powerful algorithm
                   for training machine learning architectures through
                   end-to-end differentiation. However, backprop is often
                   criticised for lacking biological plausibility. Recently, it
                   has been shown that backprop in multilayer-perceptrons
                   (MLPs) can be approximated using predictive coding, a
                   biologically-plausible process theory of cortical
                   computation which relies only on local and Hebbian updates.
                   The power of backprop, however, lies not in its
                   instantiation in MLPs, but rather in the concept of
                   automatic differentiation which allows for the optimisation
                   of any differentiable program expressed as a computation
                   graph. Here, we demonstrate that predictive coding converges
                   asymptotically (and in practice rapidly) to exact backprop
                   gradients on arbitrary computation graphs using only local
                   learning rules. We apply this result to develop a
                   straightforward strategy to translate core machine learning
                   architectures into their predictive coding equivalents. We
                   construct predictive coding CNNs, RNNs, and the more complex
                   LSTMs, which include a non-layer-like branching internal
                   graph structure and multiplicative interactions. Our models
                   perform equivalently to backprop on challenging machine
                   learning benchmarks, while utilising only local and (mostly)
                   Hebbian plasticity. Our method raises the potential that
                   standard machine learning algorithms could in principle be
                   directly implemented in neural circuitry, and may also
                   contribute to the development of completely distributed
                   neuromorphic architectures.",
  month         =  "7~" # jun,
  year          =  2020,
  url           = "http://arxiv.org/abs/2006.04182",
  file          = "All Papers/MILLIDGE/Millidge et al. 2020 - Predictive Coding Approximates Backprop along Arbitrary Computation Graphs.pdf",
  archivePrefix = "arXiv",
  eprint        = "2006.04182",
  primaryClass  = "cs.LG",
  arxivid       = "2006.04182"
}


@ARTICLE{Makridakis2022-hb,
  title    = "{M5} accuracy competition: Results, findings, and conclusions",
  author   = "Makridakis, Spyros and Spiliotis, Evangelos and Assimakopoulos,
              Vassilios",
  abstract = "In this study, we present the results of the M5 ``Accuracy''
              competition, which was the first of two parallel challenges in
              the latest M competition with the aim of advancing the theory and
              practice of forecasting. The main objective in the M5
              ``Accuracy'' competition was to accurately predict 42,840 time
              series representing the hierarchical unit sales for the largest
              retail company in the world by revenue, Walmart. The competition
              required the submission of 30,490 point forecasts for the lowest
              cross-sectional aggregation level of the data, which could then
              be summed up accordingly to estimate forecasts for the remaining
              upward levels. We provide details of the implementation of the M5
              ``Accuracy'' challenge, as well as the results and best
              performing methods, and summarize the major findings and
              conclusions. Finally, we discuss the implications of these
              findings and suggest directions for future research.",
  journal  = "International journal of forecasting",
  volume   =  38,
  number   =  4,
  pages    = "1346--1364",
  month    =  "1~" # oct,
  year     =  2022,
  url      = "https://www.sciencedirect.com/science/article/pii/S0169207021001874",
  file     = "All Papers/MAKRIDAKIS/Makridakis et al. 2022 - M5 accuracy competition - Results, findings, and conclusions.pdf",
  keywords = "Forecasting competitions; M competitions; Accuracy; Time series;
              Machine learning; Retail sales forecasting",
  issn     = "0169-2070",
  doi      = "10.1016/j.ijforecast.2021.11.013"
}


@ARTICLE{Imai2021-kk,
  title     = "On the use of two-way fixed effects regression models for causal
               inference with panel data",
  author    = "Imai, Kosuke and Kim, In Song",
  journal   = "Political analysis: an annual publication of the Methodology
               Section of the American Political Science Association",
  publisher = "Cambridge University Press (CUP)",
  volume    =  29,
  number    =  3,
  pages     = "405--415",
  abstract  = "AbstractThe two-way linear fixed effects regression (2FE) has
               become a default method for estimating causal effects from panel
               data. Many applied researchers use the 2FE estimator to adjust
               for unobserved unit-specific and time-specific confounders at the
               same time. Unfortunately, we demonstrate that the ability of the
               2FE model to simultaneously adjust for these two types of
               unobserved confounders critically relies upon the assumption of
               linear additive effects. Another common justification for the use
               of the 2FE estimator is based on its equivalence to the
               difference-in-differences estimator under the simplest setting
               with two groups and two time periods. We show that this
               equivalence does not hold under more general settings commonly
               encountered in applied research. Instead, we prove that the
               multi-period difference-in-differences estimator is equivalent to
               the weighted 2FE estimator with some observations having negative
               weights. These analytical results imply that in contrast to the
               popular belief, the 2FE estimator does not represent a
               design-based, nonparametric estimation strategy for causal
               inference. Instead, its validity fundamentally rests on the
               modeling assumptions.",
  month     =  jul,
  year      =  2021,
  url       = "https://web.mit.edu/insong/www/pdf/FEmatch-twoway.pdf",
  file      = "All Papers/IMAI/Imai and Kim 2021 - On the use of two-way fixed effects regression models for causal inference with panel data.pdf",
  doi       = "10.1017/pan.2020.33",
  issn      = "1047-1987,1476-4989",
  language  = "en"
}


@misc{enwiki:1186188179,
author = "{Wikipedia contributors}",
title = "Lorenz system --- {Wikipedia}{,} The Free Encyclopedia",
year = "2023",
url = "https://en.wikipedia.org/w/index.php?title=Lorenz_system&oldid=1186188179",
note = "[Online; accessed 23-November-2023]"
}


@INCOLLECTION{Takens1981-kh,
  title     = "Detecting strange attractors in turbulence",
  author    = "Takens, Floris",
  booktitle = "Lecture Notes in Mathematics",
  publisher = "Springer Berlin Heidelberg",
  address   = "Berlin, Heidelberg",
  pages     = "366--381",
  series    = "Lecture notes in mathematics",
  year      =  1981,
  url       = "http://dx.doi.org/10.1007/bfb0091924",
  doi       = "10.1007/bfb0091924",
  isbn      = "9783540111719,9783540389453",
  issn      = "0075-8434,1617-9692"
}
