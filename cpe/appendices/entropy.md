# Entropy


## Shannon Entropy

Shannon entropy $S$ is the expectation of information content $I(X)=-\log \left(P(X)\right)$,

\begin{equation}
\mathbb E_{P(X)}\left[ -\log \left(P(X)\right) \right].
\end{equation}




## Cross Entropy

